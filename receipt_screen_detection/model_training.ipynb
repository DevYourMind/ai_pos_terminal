{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import gc\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report, accuracy_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # colab data unar\n",
    "\n",
    "# !sudo apt install unar\n",
    "# !unar 'drive/MyDrive/sorted_data_merged.rar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формирование выборки для обучения и теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_markup = pd.read_pickle('df_markup.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_augm = df_markup['filename'].apply(lambda x: 'augm' in x)\n",
    "train_augm = df_markup.loc[\n",
    "    flag_augm\n",
    "]\n",
    "df_markup = df_markup.loc[~flag_augm]\n",
    "train, test = train_test_split(\n",
    "    df_markup, stratify=df_markup['target'], \n",
    "    random_state=RANDOM_STATE, test_size=TEST_SIZE)\n",
    "train = pd.concat((train, train_augm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pc_screen    6499\n",
       "receipt      3626\n",
       "other        3224\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "receipt      640\n",
       "other        569\n",
       "pc_screen     90\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Augment train data\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.RandomCrop((500, 500)),\n",
    "    transforms.RandomHorizontalFlip(p=1),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# Don't augment test data, only reshape\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_label = {\n",
    "    'other': 0,\n",
    "    'pc_screen': 1,\n",
    "    'receipt': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_column, transform=None, filename=False):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "        self.target_column = target_column\n",
    "        self.filename = filename\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = dict_label[self.data.iloc[idx][self.target_column]]\n",
    "        file_name = self.data.iloc[idx]['filename']\n",
    "        img = Image.open(file_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.filename:\n",
    "            return img, label, file_name\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 0\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = CustomDataset(train, target_column='target', transform=train_transforms)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataset = CustomDataset(test, target_column='target', transform=test_transforms)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = 'models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "def plot_losses(train_losses,\n",
    "            test_losses,\n",
    "            train_accuracies,\n",
    "            test_accuracies,\n",
    "            train_f1s,\n",
    "            test_f1s,\n",
    "            train_precisions,\n",
    "            test_precisions,\n",
    "            train_recalls,\n",
    "            test_recalls):\n",
    "    clear_output()\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "    plt.rcParams['font.size'] = '12'\n",
    "    axs[0, 0].plot(range(1, len(train_losses) + 1), train_losses, label='train', marker='o')\n",
    "    axs[0, 0].plot(range(1, len(test_losses) + 1), test_losses, label='test', marker='o')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    axs[0, 1].plot(range(1, len(train_accuracies) + 1), train_accuracies, label='train', marker='o')\n",
    "    axs[0, 1].plot(range(1, len(test_accuracies) + 1), test_accuracies, label='test', marker='o')\n",
    "    axs[0, 1].set_ylabel('Accuracy')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    axs[0, 2].plot(range(1, len(train_f1s) + 1), train_f1s, label='train', marker='o')\n",
    "    axs[0, 2].plot(range(1, len(test_f1s) + 1), test_f1s, label='test', marker='o')\n",
    "    axs[0, 2].set_ylabel('F1')\n",
    "    axs[0, 2].legend()\n",
    "\n",
    "    axs[1, 0].plot(range(1, len(train_precisions) + 1), train_precisions, label='train', marker='o')\n",
    "    axs[1, 0].plot(range(1, len(test_precisions) + 1), test_precisions, label='test', marker='o')\n",
    "    axs[1, 0].set_ylabel('Precision')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    axs[1, 1].plot(range(1, len(train_recalls) + 1), train_recalls, label='train', marker='o')\n",
    "    axs[1, 1].plot(range(1, len(test_recalls) + 1), test_recalls, label='test', marker='o')\n",
    "    axs[1, 1].set_ylabel('Recall')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    # for ax in axs:\n",
    "    #     ax.set_xlabel('epoch')\n",
    "    #     ax.legend()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.show()\n",
    "\n",
    "def training_epoch(model, optimizer, criterion, train_loader, tqdm_desc):\n",
    "    train_loss, train_accuracy, train_f1, train_precision, train_recall = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_loader, desc=tqdm_desc):\n",
    "        images = images.to(device)  # images: batch_size x num_channels x height x width\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "        # labels = labels.to(device)  # labels: batch_size\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)  # logits: batch_size x num_classes\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.shape[0]\n",
    "        train_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        # Calculate F1-score\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        train_f1 += f1_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "        train_precision += precision_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "        train_recall += recall_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy /= len(train_loader.dataset)\n",
    "    train_f1 /= len(train_loader)\n",
    "    train_precision /= len(train_loader)\n",
    "    train_recall /= len(train_loader)\n",
    "\n",
    "    return train_loss, train_accuracy, train_f1, train_precision, train_recall\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_epoch(model, criterion, test_loader, tqdm_desc):\n",
    "    test_loss, test_accuracy, test_f1, test_precision, test_recall = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    model.eval()\n",
    "    for images, labels in tqdm(test_loader, desc=tqdm_desc):\n",
    "        images = images.to(device)  # images: batch_size x num_channels x height x width\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "        # labels = labels.to(device)  # labels: batch_size\n",
    "        logits = model(images)  # logits: batch_size x num_classes\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        test_loss += loss.item() * images.shape[0]\n",
    "        test_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n",
    "        # Calculate F1-score\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        test_f1 += f1_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "        test_precision += precision_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "        test_recall += recall_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy /= len(test_loader.dataset)\n",
    "    test_f1 /= len(test_loader)\n",
    "    test_precision /= len(test_loader)\n",
    "    test_recall /= len(test_loader)\n",
    "\n",
    "    return test_loss, test_accuracy, test_f1, test_precision, test_recall\n",
    "\n",
    "\n",
    "def train(model, optimizer, scheduler, criterion, train_loader, test_loader, num_epochs):\n",
    "    train_losses, train_accuracies, train_f1s, train_precisions, train_recalls = [], [], [], [], []\n",
    "    test_losses, test_accuracies, test_f1s, test_precisions, test_recalls = [], [], [], [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_accuracy, train_f1, train_precision, train_recall = training_epoch(\n",
    "            model, optimizer, criterion, train_loader,\n",
    "            tqdm_desc=f'Training {epoch}/{num_epochs}'\n",
    "        )\n",
    "        test_loss, test_accuracy, test_f1, test_precision, test_recall = validation_epoch(\n",
    "            model, criterion, test_loader,\n",
    "            tqdm_desc=f'Validating {epoch}/{num_epochs}'\n",
    "        )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_losses += [train_loss]\n",
    "        train_accuracies += [train_accuracy]\n",
    "        train_f1s += [train_f1]\n",
    "        train_precisions += [train_precision]\n",
    "        train_recalls += [train_recall]\n",
    "\n",
    "        test_losses += [test_loss]\n",
    "        test_accuracies += [test_accuracy]\n",
    "        test_f1s += [test_f1]\n",
    "        test_precisions += [test_precision]\n",
    "        test_recalls += [test_recall]\n",
    "        plot_losses(\n",
    "            train_losses,\n",
    "            test_losses,\n",
    "            train_accuracies,\n",
    "            test_accuracies,\n",
    "            train_f1s,\n",
    "            test_f1s,\n",
    "            train_precisions,\n",
    "            test_precisions,\n",
    "            train_recalls,\n",
    "            test_recalls\n",
    "          )\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_losses[-1],\n",
    "            'test_loss': test_losses[-1],\n",
    "            'train_accuracy': train_accuracies[-1],\n",
    "            'test_accuracy': test_accuracies[-1],\n",
    "            'train_f1': train_f1s[-1],\n",
    "            'test_f1': test_f1s[-1],\n",
    "            'train_precision': train_precisions[-1],\n",
    "            'test_precision': test_precisions[-1],\n",
    "            'train_recall': train_recalls[-1],\n",
    "            'test_recall': test_recalls[-1]\n",
    "        }, models_dir+f'/model_terminal_quality_ep{epoch}.pth')\n",
    "\n",
    "    return train_losses, test_losses, train_accuracies, test_accuracies, train_f1s, test_f1s, train_precisions, test_precisions, train_recalls, test_recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_receipt = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT)\n",
    "model_receipt.classifier[3] = torch.nn.Linear(1280, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "model_receipt = model_receipt.to(device)\n",
    "optimizer = torch.optim.SGD(model_receipt.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses, train_accuracies, test_accuracies, train_f1s, test_f1s = train(\n",
    "    model_receipt, optimizer, scheduler, criterion, train_dataloader, test_dataloader, num_epochs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
