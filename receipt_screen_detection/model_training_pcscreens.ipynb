{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFile\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # colab data unar\n",
    "\n",
    "# !sudo apt install unar\n",
    "# !unar 'drive/MyDrive/sorted_data_merged.rar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формирование выборки для обучения и теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_markup = pd.read_pickle('df_markup.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_markup.loc[\n",
    "    df_markup['target']!='pc_screen', 'target'\n",
    "] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_augm = df_markup['filename'].apply(lambda x: 'augm' in x)\n",
    "train_augm = df_markup.loc[\n",
    "    flag_augm\n",
    "]\n",
    "df_markup = df_markup.loc[~flag_augm]\n",
    "train, test = train_test_split(\n",
    "    df_markup, stratify=df_markup['target'], \n",
    "    random_state=RANDOM_STATE, test_size=TEST_SIZE)\n",
    "train = pd.concat((train, train_augm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pc_screen    7272\n",
       "other        3583\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other        1195\n",
       "pc_screen      91\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Augment train data\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.RandomCrop((500, 500)),\n",
    "    transforms.RandomHorizontalFlip(p=1),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# Don't augment test data, only reshape\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_label = {\n",
    "    'other': 0,\n",
    "    'pc_screen': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_column, transform=None, filename=False):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "        self.target_column = target_column\n",
    "        self.filename = filename\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = dict_label[self.data.iloc[idx][self.target_column]]\n",
    "        file_name = self.data.iloc[idx]['filename']\n",
    "        img = Image.open(file_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.filename:\n",
    "            return img, label, file_name\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 0\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = CustomDataset(train, target_column='target', transform=train_transforms)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataset = CustomDataset(test, target_column='target', transform=test_transforms)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = 'models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "def plot_losses(train_losses,\n",
    "            test_losses,\n",
    "            train_accuracies,\n",
    "            test_accuracies,\n",
    "            train_f1s,\n",
    "            test_f1s,\n",
    "            train_precisions,\n",
    "            test_precisions,\n",
    "            train_recalls,\n",
    "            test_recalls):\n",
    "    clear_output()\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "    plt.rcParams['font.size'] = '12'\n",
    "    axs[0, 0].plot(range(1, len(train_losses) + 1), train_losses, label='train', marker='o')\n",
    "    axs[0, 0].plot(range(1, len(test_losses) + 1), test_losses, label='test', marker='o')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    axs[0, 1].plot(range(1, len(train_accuracies) + 1), train_accuracies, label='train', marker='o')\n",
    "    axs[0, 1].plot(range(1, len(test_accuracies) + 1), test_accuracies, label='test', marker='o')\n",
    "    axs[0, 1].set_ylabel('Accuracy')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    axs[0, 2].plot(range(1, len(train_f1s) + 1), train_f1s, label='train', marker='o')\n",
    "    axs[0, 2].plot(range(1, len(test_f1s) + 1), test_f1s, label='test', marker='o')\n",
    "    axs[0, 2].set_ylabel('F1')\n",
    "    axs[0, 2].legend()\n",
    "\n",
    "    axs[1, 0].plot(range(1, len(train_precisions) + 1), train_precisions, label='train', marker='o')\n",
    "    axs[1, 0].plot(range(1, len(test_precisions) + 1), test_precisions, label='test', marker='o')\n",
    "    axs[1, 0].set_ylabel('Precision')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    axs[1, 1].plot(range(1, len(train_recalls) + 1), train_recalls, label='train', marker='o')\n",
    "    axs[1, 1].plot(range(1, len(test_recalls) + 1), test_recalls, label='test', marker='o')\n",
    "    axs[1, 1].set_ylabel('Recall')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    # for ax in axs:\n",
    "    #     ax.set_xlabel('epoch')\n",
    "    #     ax.legend()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.show()\n",
    "\n",
    "def training_epoch(model, optimizer, criterion, train_loader, tqdm_desc):\n",
    "    train_loss, train_accuracy, train_f1, train_precision, train_recall = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_loader, desc=tqdm_desc):\n",
    "        images = images.to(device)  # images: batch_size x num_channels x height x width\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "        # labels = labels.to(device)  # labels: batch_size\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)  # logits: batch_size x num_classes\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.shape[0]\n",
    "        train_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        # Calculate F1-score\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        train_f1 += f1_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "        train_precision += precision_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "        train_recall += recall_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy /= len(train_loader.dataset)\n",
    "    train_f1 /= len(train_loader)\n",
    "    train_precision /= len(train_loader)\n",
    "    train_recall /= len(train_loader)\n",
    "\n",
    "    return train_loss, train_accuracy, train_f1, train_precision, train_recall\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_epoch(model, criterion, test_loader, tqdm_desc):\n",
    "    test_loss, test_accuracy, test_f1, test_precision, test_recall = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    model.eval()\n",
    "    for images, labels in tqdm(test_loader, desc=tqdm_desc):\n",
    "        images = images.to(device)  # images: batch_size x num_channels x height x width\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "        # labels = labels.to(device)  # labels: batch_size\n",
    "        logits = model(images)  # logits: batch_size x num_classes\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        test_loss += loss.item() * images.shape[0]\n",
    "        test_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n",
    "        # Calculate F1-score\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        test_f1 += f1_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "        test_precision += precision_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "        test_recall += recall_score(labels.cpu().numpy(), predictions.cpu().numpy(), average='macro')\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy /= len(test_loader.dataset)\n",
    "    test_f1 /= len(test_loader)\n",
    "    test_precision /= len(test_loader)\n",
    "    test_recall /= len(test_loader)\n",
    "\n",
    "    return test_loss, test_accuracy, test_f1, test_precision, test_recall\n",
    "\n",
    "\n",
    "def train(model, optimizer, scheduler, criterion, train_loader, test_loader, num_epochs, target='receipt'):\n",
    "    train_losses, train_accuracies, train_f1s, train_precisions, train_recalls = [], [], [], [], []\n",
    "    test_losses, test_accuracies, test_f1s, test_precisions, test_recalls = [], [], [], [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_accuracy, train_f1, train_precision, train_recall = training_epoch(\n",
    "            model, optimizer, criterion, train_loader,\n",
    "            tqdm_desc=f'Training {epoch}/{num_epochs}'\n",
    "        )\n",
    "        test_loss, test_accuracy, test_f1, test_precision, test_recall = validation_epoch(\n",
    "            model, criterion, test_loader,\n",
    "            tqdm_desc=f'Validating {epoch}/{num_epochs}'\n",
    "        )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_losses += [train_loss]\n",
    "        train_accuracies += [train_accuracy]\n",
    "        train_f1s += [train_f1]\n",
    "        train_precisions += [train_precision]\n",
    "        train_recalls += [train_recall]\n",
    "\n",
    "        test_losses += [test_loss]\n",
    "        test_accuracies += [test_accuracy]\n",
    "        test_f1s += [test_f1]\n",
    "        test_precisions += [test_precision]\n",
    "        test_recalls += [test_recall]\n",
    "        plot_losses(\n",
    "            train_losses,\n",
    "            test_losses,\n",
    "            train_accuracies,\n",
    "            test_accuracies,\n",
    "            train_f1s,\n",
    "            test_f1s,\n",
    "            train_precisions,\n",
    "            test_precisions,\n",
    "            train_recalls,\n",
    "            test_recalls\n",
    "          )\n",
    "        torch.save(model, models_dir+f'/model_{target}_ep{epoch}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_losses[-1],\n",
    "            'test_loss': test_losses[-1],\n",
    "            'train_accuracy': train_accuracies[-1],\n",
    "            'test_accuracy': test_accuracies[-1],\n",
    "            'train_f1': train_f1s[-1],\n",
    "            'test_f1': test_f1s[-1],\n",
    "            'train_precision': train_precisions[-1],\n",
    "            'test_precision': test_precisions[-1],\n",
    "            'train_recall': train_recalls[-1],\n",
    "            'test_recall': test_recalls[-1]\n",
    "        }, models_dir+f'/model_{target}_ep{epoch}.pth')\n",
    "\n",
    "    return train_losses, test_losses, train_accuracies, test_accuracies, train_f1s, test_f1s, train_precisions, test_precisions, train_recalls, test_recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pcscreen = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT)\n",
    "model_pcscreen.classifier[3] = torch.nn.Linear(1280, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "model_pcscreen = model_pcscreen.to(device)\n",
    "optimizer = torch.optim.SGD(model_pcscreen.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training 1/40:   0%|          | 0/356 [00:00<?, ?it/s]C:\\Users\\dimaz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Training 1/40:   0%|          | 1/356 [00:29<2:54:03, 29.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\projects\\ai_pos_terminal\\ai_pos_terminal\\receipt_screen_detection\\model_training_pcscreens.ipynb Cell 26\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_losses, test_losses, train_accuracies, test_accuracies, train_f1s, test_f1s, train_precisions, test_precisions, train_recalls, test_recalls \u001b[39m=\u001b[39m train(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model_pcscreen, optimizer, scheduler, criterion, train_dataloader, test_dataloader, num_epochs, target\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpc_screen\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "\u001b[1;32md:\\projects\\ai_pos_terminal\\ai_pos_terminal\\receipt_screen_detection\\model_training_pcscreens.ipynb Cell 26\u001b[0m line \u001b[0;36mtrain\u001b[1;34m(model, optimizer, scheduler, criterion, train_loader, test_loader, num_epochs, target)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m test_losses, test_accuracies, test_f1s, test_precisions, test_recalls \u001b[39m=\u001b[39m [], [], [], [], []\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m     train_loss, train_accuracy, train_f1, train_precision, train_recall \u001b[39m=\u001b[39m training_epoch(\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m         model, optimizer, criterion, train_loader,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m         tqdm_desc\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTraining \u001b[39;49m\u001b[39m{\u001b[39;49;00mepoch\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mnum_epochs\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m     )\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m     test_loss, test_accuracy, test_f1, test_precision, test_recall \u001b[39m=\u001b[39m validation_epoch(\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m         model, criterion, test_loader,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m         tqdm_desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidating \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m     )\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m     \u001b[39mif\u001b[39;00m scheduler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32md:\\projects\\ai_pos_terminal\\ai_pos_terminal\\receipt_screen_detection\\model_training_pcscreens.ipynb Cell 26\u001b[0m line \u001b[0;36mtraining_epoch\u001b[1;34m(model, optimizer, criterion, train_loader, tqdm_desc)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m logits \u001b[39m=\u001b[39m model(images)  \u001b[39m# logits: batch_size x num_classes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, labels)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/ai_pos_terminal/ai_pos_terminal/receipt_screen_detection/model_training_pcscreens.ipynb#X34sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m images\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, train_accuracies, test_accuracies, train_f1s, test_f1s, train_precisions, test_precisions, train_recalls, test_recalls = train(\n",
    "    model_pcscreen, optimizer, scheduler, criterion, train_dataloader, test_dataloader, num_epochs, target='pc_screen'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels, all_preds_pcscreen = [], [], []\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.to(device)  # images: batch_size x num_channels x height x width\n",
    "    predictions_pcscreen = model_pcscreen(images).argmax(dim=1)\n",
    "    all_labels.append(labels)\n",
    "    all_preds_pcscreen.append(predictions_pcscreen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_pcscreen = [torch.Tensor.cpu(x).numpy() for x in all_preds_pcscreen]\n",
    "df_val = pd.DataFrame({\n",
    "    'labels': np.hstack(all_labels),\n",
    "    'predictions_pcscreen': np.hstack(all_preds_pcscreen)\n",
    "})\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(\n",
    "    df_val['labels'], \n",
    "    df_val['predictions_pcscreen'], \n",
    "    labels=[0, 1]\n",
    ")\n",
    "class_names = ['Не экран', 'Экран']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Прогнозы модели')\n",
    "plt.ylabel('Настоящие метки')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
